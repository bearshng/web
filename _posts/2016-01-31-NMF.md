---
layout: post
title:  非负矩阵分解
date:   2016-01-31 12:53
categories: 机器学习
tags: NMF
---

在篇博文里面，我将对我所了解的非负矩阵分解进行介绍。主要对非负矩阵分解的概念以及它相关的应用进行介绍。

## 奇异值分解 ##

要对非负矩阵分解进行介绍，首先我们必须先了解一下奇异值分解(singular value decomposition),简称为SVD。在SVD中我们对于任异一个$m \times n$的矩阵M，它的SVD分解的形式为：
\[M = U\Sigma {V^T}\]

其中$U$和$V$是两个单位正交矩阵，分别称作矩阵$M$的左右奇异值，矩阵$\Sigma$ 为一个对角矩阵，它的每一个元素称为矩阵$M$的奇异值，对应为普分解([https://en.wikipedia.org/wiki/Eigendecomposition_of_a_matrix](https://en.wikipedia.org/wiki/Eigendecomposition_of_a_matrix "Spectral decomposition"))中特征值的平方。我们知道谱分解要求矩阵必须是方阵，而且谱分解不唯一。和谱分解不同的是，任何一个矩阵都有它的奇异值分解而且它的奇异值分解是唯一的。

### 奇异值分解与PCA ###

在奇异值分解中如果我们取$\Sigma$的前K个最大值作为矩阵$M$的近似，即
$M =\sum\nolimits\_{i = 1}^k { \{u\_i} {\sigma\_i} } {v\_i}^T$,这个性质在Principal component analysis ([PCA](https://en.wikipedia.org/wiki/Principal_component_analysis "PCA")) 分解中也有所应用。因为在PCA为了减少数据集的维数，同时保持数据集中的对方差贡献最大的特征。我们通过对协方差矩阵进行分解保留低阶主成分，忽略高阶主成分做到。这样低阶成分往往能够保留住数据的最重要方面。它数学定义为：我们通过一个正交化线性变换，把数据变换到一个新的坐标系统中，使得这一数据的任何投影的第一大方差在第一个坐标（称为第一主成分）上，第二大方差在第二个坐标（第二主成分）上，依次类推，这个刚好和奇异值分解反应的性质一样。


### 奇异值分解与Latent semantic indexing (LSI)  ###

传统向量空间模型使用精确的词匹配，即精确匹配用户输入的词与向量空间中存在的词。由于一词多义(polysemy)和一义多词(synonymy)的存在，使得该模型无法提供给用户语义层面的检索。比如用户搜索”automobile”，即汽车，传统向量空间模型仅仅会返回包含”automobile”单词的页面，而实际上包含”car”单词的页面也可能是用户所需要的。

潜在语义分析([LSI](https://en.wikipedia.org/wiki/Latent_semantic_indexing "LSI"))的目的，就是要找出词(terms)在文档和查询中真正的含义，也就是潜在语义，从而解决上节所描述的问题。具体说来就是对一个大型的文档集合使用一个合理的维度建模，并将词和文档都表示到该空间，比如有2000个文档，包含7000个索引词，LSI使用一个维度为100的向量空间将文档和词表示到该空间，进而在该空间进行信息检索。而将文档表示到此空间的过程就是SVD奇异值分解和降维的过程。我们对一个Word-Document矩阵$M$进行SVD分解得到

\\[M \approx {\rm{ }}{U^{\left( k \right)}}{\Sigma ^{\left( k \right)}}{V^{\left( k \right)}}^T\]\\]

，其中$U$我们称为潜在语义或者是topic。这样我们在计算两个文档$M\_i$和$M\_j$的相似度的时候我们可以把两个文档在矩阵$\U$上作投影然后再计算相似度，即

\\[\left. {\left\langle {\{M\_i}^TU,\{M\_j}^TU} \right.} \right\rangle \\]

但是LSI中的topic有以下两个缺点

1. "主题"是单位正交的
	
考虑主题“政治”和“金融”，我们很难说这两个主题正交(无关)

1. 主题中存在负的数值

主题中存在负数表示某一个单词不属于某一个topic，这个在一些具体的应用中会有所影响，具体我也没有想好为什么会有所影响....但是在一个文档中这样描述

    But then when we compute similarly, two documents are
    judged to be more similar based on a topic that they are both decidedly not about.This is another counter intuitive and undesirable property


## 非负矩阵分解##

在非负矩阵分解中我们对一个矩阵$M$进行非负近似即：
\\[M \approx AW \\]
其中矩阵$A$和矩阵$W$分别为$m \times k$和$k \times n$的非负矩阵。一个简单的图示如下：
<img src="/assets/img/201601/nmf.png" style="width:500px;vertical-align:middle;"alt="NMF"  />

在这个图中我们把一个矩阵$Y$表示为$k$个非负的向量$a$和$k$个非负向量$b$乘鸡的形式。其中矩阵$E$在实际应用中表示噪声。
和SVD不同的是NMF是不唯一的，因为我们显然可以找到一个对角矩阵$D$使得$M \approx AD{D^{ - 1}}W$ 如果我们取$\mathop A\limits^\~  = AD\$，$\mathop M\limits^\~  = {D^{ - 1}}W$，我们可以得到矩阵M的另外一个非负近似为：
\\[M \approx \mathop A\limits^\~ \mathop W\limits^\~ \\]

所以我们一般会对矩阵$A$和矩阵$W$作一些约束,比如说稀疏，或者sum-to-one等等。非负矩阵分解在一些领域也有很多的应用，比如说在高光谱图像解混([Hyperspectral Unmixing](https://www.google.com.hk/url?sa=t&rct=j&q=&esrc=s&source=web&cd=1&cad=rja&uact=8&ved=0ahUKEwjfr8HfutTKAhUCOiYKHeWIB1EQFggcMAA&url=http%3A%2F%2Fwww.lx.it.pt%2F~bioucas%2Ffiles%2Fieee_jstars_unmixing_overview_12.pdf&usg=AFQjCNE4yDbkWSzBzHI503jjjVARUEd80A "HyperSpectral Unmixing"))，文本的聚类等。


##非负矩阵的求解##

当我们不知道矩阵的rank r的时候，显然对于NMF，它是一个NP-hard 问题，因为我们只能对矩阵的rank进行不断的遍历求解。如果我们知道rank r我们可以通过EM的方法对矩阵进行求解。它的主要idea是，我们先对矩阵$A$和$W$进行随机猜一个数值，然后进行不断的迭代，求解直到收敛。一般在非负矩阵求解中有两种方法一个是乘法更新方法，另外一种是ALS方法。下面我们对这两种方法进行介绍。

###乘法更新求解NMF###
在乘法更新中目标函数的表达式为
<img src="/assets/img/201601/muobj.png" style="width:500px;vertical-align:middle;"alt="NMF"  />
然后我们对这个目标函数表达式求解KKT条件得到如下：
<img src="/assets/img/201601/muKKT.png" style="width:500px;vertical-align:middle;"alt="NMF"  />
其中梯度的表达式为：
<img src="/assets/img/201601/mugradient.png" style="width:500px;vertical-align:middle;"alt="NMF"  />
结合上述的两组式子我们得到：
<img src="/assets/img/201601/mu2.png" style="width:500px;vertical-align:middle;"alt="NMF"  />
即更新的规则为:

<img src="/assets/img/201601/muUpdate.png" style="width:500px;vertical-align:middle;"alt="NMF"  />

###最小二乘求解NMF###

在最小二乘中目标函数的表达式为
<img src="/assets/img/201601/muobj.png" style="width:500px;vertical-align:middle;"alt="NMF"  />
然后我们对这个目标函数表达式求解KKT条件得到如下：
<img src="/assets/img/201601/muKKT.png" style="width:500px;vertical-align:middle;"alt="NMF"  />
求解梯度我们得到：

<img src="/assets/img/201601/ALSgradient.png" style="width:500px;vertical-align:middle;"alt="NMF"  />


即更新的规则为:

<img src="/assets/img/201601/ALSUpdate.png" style="width:500px;vertical-align:middle;"alt="NMF"  />


###非负矩阵收敛证明###







